# -*- coding: utf-8 -*-
"""Untitled5.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1YPN4FxNmxLuiI21VVWzBlSMvWtq9RUs0
"""

import pandas as pd
import zipfile
import glob
import chardet

# Get the zip file path
zip_file_path = glob.glob('/content/Property_data-20250109T060831Z-001.zip')[0]

# Open the zip file
with zipfile.ZipFile(zip_file_path, 'r') as zip_file:
    # Get a list of all CSV files within the zip
    csv_files = [file for file in zip_file.namelist() if file.endswith('.csv')]

    # Create a list to store dataframes
    dfs = []

    # Iterate through each CSV file, read it into a dataframe, and append to the list
    for csv_file in csv_files:
        with zip_file.open(csv_file) as f:
            # Detect encoding
            rawdata = f.read()
            result = chardet.detect(rawdata)
            encoding = result['encoding']

            # Reset file pointer to beginning
            f.seek(0)

            df = pd.read_csv(f, encoding=encoding)  # Read the CSV file using detected encoding
            dfs.append(df)  # Add the dataframe to the list

# Use pd.read_csv with the delimiter='\t' for reading TSV files
dfg = pd.read_csv('/content/property_photos (1).tsv', delimiter='\t')
dfs.append(dfg)

dfi=pd.read_csv('/content/property_interactions.csv')
dfs.append(dfi)
print(dfs)
# Concatenate all dataframes in the list
merged_df = pd.concat(dfs, ignore_index=True)
merged_df.head()

# Print the columns of your DataFrame to see if 'photo_urls' is there
print(merged_df.columns)
print(merged_df['location'])

# If 'photo_urls' is not present, check the original CSV files for the correct column name
# If it's a typo, correct the column name in your code
# If the column was dropped in a previous step, you'll need to reload the original data or adjust your code to avoid using that column.

# Assuming 'photo_urls' is the actual column name and it is present
# Replace the column name in the following line with the correct one if it's different
merged_df['photo_count'] = merged_df['photo_urls'].apply(extract_photo_count)

import json

def extract_photo_count(photo_urls):
  try:
    photos=json.loads(photo_urls.replace("'",'"'))
    return len(photos)
  except:
    return 0

# Assuming 'photo_urls' column exists in merged_df
# Replace 'merged_df' with the correct DataFrame name if different
merged_df['photo_count'] = merged_df['photo_urls'].apply(extract_photo_count)

interactions_df = merged_df.groupby('property_id').size().reset_index(name='total_interactions')
# OR to this if you want a separate dataframe called property_interactions instead of merging
property_interactions = pd.read_csv('/content/property_interactions.csv')
interactions_df = property_interactions.groupby('property_id').size().reset_index(name='total_interactions')

final_df = merged_df.merge(merged_df[['property_id','photo_count']],on='property_id',how='left')

final_df=final_df.merge(interactions_df,on='property_id',how='left')

import seaborn as sns
import matplotlib.pyplot as plt

sns.boxplot(x='furnishing',y='rent',data=final_df)
plt.title('Rent Distribution by Furnishing Type')
plt.show()

hsr_properties=merged_df[merged_df['locality']=='HSR_layout'].shape[0]
hsr_properties

total_properties = merged_df.shape[0]

percentage_hsr=(hsr_properties/total_properties)*1000
print(percentage_hsr)

uniq_location=merged_df['locality'].unique()
len(uniq_location)

avg_rent=merged_df.groupby('locality')['rent'].mean().reset_index()
hig_rent=avg_rent.sort_values(by='rent',ascending=False)
hig_rent

merged_df['activation_date']=pd.to_datetime(merged_df['activation_date'])
merged_df['request_date']=pd.to_datetime(merged_df['request_date'])
merged_df['days_since_activation']=(merged_df['request_date']-merged_df['activation_date']).dt.days

int_wit_7d=merged_df[merged_df['days_since_activation']<=7]
int_wit_7d

total_interaction_7d=int_wit_7d.groupby('property_id').size().reset_index(name='total_interactions')
total_interaction_7d

m_c = total_interaction_7d['total_interactions'].mode()
if not m_c.empty:
    m_c = m_c.iloc[0]  # Access the first element if mode is not empty
else:
    m_c = None  # or handle the case where mode is empty (e.g., assign a default value)

print(m_c)

b=[0,1,5,10,20,float('inf')]
labels =['New','Less than 5 years','5-10 years','10-20 years', 'More than 20 years']
merged_df['property_age']=pd.cut(merged_df['days_since_activation'],bins=b,labels=labels,right=False)

mode_value = merged_df['property_age'].mode()
if not mode_value.empty:
    print(mode_value.iloc[0])  # Access the first element using iloc if mode is not empty
else:
    print("No mode found")  # Handle the case where mode is empty

# Change the variable name from 'property_interactions_df' to 'property_interactions'
total_interaction = property_interactions.groupby('property_id').size().reset_index(name='total_interactions_count') #Rename the column here to avoid conflict

# Merge total_interaction with merged_df on 'property_id'
merged_df = merged_df.merge(total_interaction, on='property_id', how='left')

# Calculate the average total_interactions for each property type
a_i = merged_df.groupby('type')['total_interactions_count'].mean().reset_index() #Use the new name here
a_i=a_i.sort_values(by='total_interactions_count',ascending=False) # Use the new name here
a_i

# Change the variable name from 'property_interactions_df' to 'property_interactions'
total_interaction = property_interactions.groupby('property_id').size().reset_index(name='total_interactions')
total_interaction